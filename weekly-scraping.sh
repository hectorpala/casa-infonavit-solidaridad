#!/bin/bash

##############################################################################
# SCRIPT DE SCRAPING SEMANAL - INMUEBLES24
##############################################################################
#
# AutomatizaciÃ³n completa del pipeline:
# 1. Extractor â†’ 2. Auditor â†’ 3. Lote Manager â†’ 4. Orquestador â†’ 5. Reporte
#
# Uso:
#   ./weekly-scraping.sh
#   ./weekly-scraping.sh --notify slack
#   ./weekly-scraping.sh --dry-run
#
# ConfiguraciÃ³n:
#   Editar las variables SEARCH_URL, PRICE_RANGE, etc. abajo
#
# Cron (ejecutar cada lunes a las 2 AM):
#   0 2 * * 1 cd /path/to/project && ./weekly-scraping.sh --notify slack
#
##############################################################################

set -e  # Exit on error

# ============================================================================
# CONFIGURACIÃ“N
# ============================================================================

# URL de bÃºsqueda en Inmuebles24
SEARCH_URL="https://www.inmuebles24.com/venta/casas/culiacan-sinaloa/3000000-4000000-pesos/"

# Metadata del lote
PRICE_RANGE="3M-4M"
CITY="CuliacÃ¡n, Sinaloa"
PROPERTY_TYPE="Casas en Venta"
NOTES="Lote automÃ¡tico semanal - $(date +%Y-%m-%d)"

# Opciones
DRY_RUN=""
NOTIFY_TYPE=""

# Procesar argumentos
for arg in "$@"; do
    case $arg in
        --dry-run)
            DRY_RUN="--dry-run"
            echo "âš ï¸  MODO DRY RUN ACTIVADO"
            ;;
        --notify)
            shift
            NOTIFY_TYPE="--notify $1"
            echo "ğŸ“¬ Notificaciones activadas: $1"
            ;;
    esac
done

# ============================================================================
# FUNCIONES AUXILIARES
# ============================================================================

log() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1"
}

log_section() {
    echo ""
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "  $1"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo ""
}

# ============================================================================
# PIPELINE COMPLETO
# ============================================================================

log_section "ğŸš€ INICIANDO PIPELINE DE SCRAPING SEMANAL"

# PASO 1: EXTRACTOR
log_section "ğŸ“¥ PASO 1: EXTRACTOR DE URLS"
log "Extrayendo URLs desde Inmuebles24..."

node 1extractorurlinmuebles24.js "$SEARCH_URL"

# Encontrar el archivo mÃ¡s reciente
LATEST_URLS=$(ls -t urls-inmuebles24-*-valid.txt 2>/dev/null | head -1)

if [ -z "$LATEST_URLS" ]; then
    log "âŒ ERROR: No se generÃ³ archivo de URLs"
    exit 1
fi

log "âœ… URLs extraÃ­das: $LATEST_URLS"

# Contar URLs
URL_COUNT=$(wc -l < "$LATEST_URLS")
log "ğŸ“Š Total de URLs extraÃ­das: $URL_COUNT"

if [ "$URL_COUNT" -eq 0 ]; then
    log "âš ï¸  No se encontraron URLs nuevas. Terminando."
    exit 0
fi

# PASO 2: AUDITOR
log_section "ğŸ” PASO 2: AUDITOR DE URLS"
log "Auditando URLs y detectando duplicadas..."

node auditor-urls-inmuebles24.js "$LATEST_URLS"

# Encontrar archivo de nuevas URLs
LATEST_AUDIT=$(ls -t audit-*-nuevas.txt 2>/dev/null | head -1)

if [ -z "$LATEST_AUDIT" ]; then
    log "âŒ ERROR: No se generÃ³ archivo de auditorÃ­a"
    exit 1
fi

log "âœ… AuditorÃ­a completada: $LATEST_AUDIT"

# Contar nuevas URLs
NEW_URL_COUNT=$(wc -l < "$LATEST_AUDIT")
log "ğŸ“Š URLs nuevas (no duplicadas): $NEW_URL_COUNT"

if [ "$NEW_URL_COUNT" -eq 0 ]; then
    log "âš ï¸  No hay URLs nuevas para procesar. Todas son duplicadas."
    exit 0
fi

# PASO 3: LOTE MANAGER
log_section "ğŸ“¦ PASO 3: GESTOR DE LOTES"
log "Creando lote con metadata..."

node lote-manager.js init "$LATEST_AUDIT" \
    --rango-precio "$PRICE_RANGE" \
    --ciudad "$CITY" \
    --tipo "$PROPERTY_TYPE" \
    --notas "$NOTES"

log "âœ… Lote creado exitosamente"

# Mostrar status del lote
log "ğŸ“Š Status del lote:"
node lote-manager.js status | grep -A 20 "PROGRESO:"

# PASO 4: ORQUESTADOR
log_section "ğŸ¯ PASO 4: ORQUESTADOR DE SCRAPING"
log "Iniciando scraping automÃ¡tico con reintentos..."

if [ -n "$DRY_RUN" ]; then
    log "âš ï¸  Ejecutando en modo DRY RUN (sin scrapear realmente)"
fi

node orchestrator.js $DRY_RUN $NOTIFY_TYPE

log "âœ… OrquestaciÃ³n completada"

# PASO 5: REPORTE FINAL
log_section "ğŸ“Š PASO 5: REPORTE FINAL"

# Encontrar Ãºltimo reporte del orquestador
LATEST_REPORT=$(ls -t reports/orchestrator-*.json 2>/dev/null | head -1)

if [ -z "$LATEST_REPORT" ]; then
    log "âš ï¸  No se encontrÃ³ reporte del orquestador"
else
    log "ğŸ“„ Reporte generado: $LATEST_REPORT"
    echo ""

    # Mostrar resumen usando jq
    if command -v jq &> /dev/null; then
        log "ğŸ“ˆ Resumen de resultados:"
        jq -r '
            "  Total procesadas: \(.summary.totalUrls)",
            "  âœ… Exitosas: \(.summary.successful) (\(.summary.successRate))",
            "  âŒ Fallidas: \(.summary.failed)",
            "  ğŸ”„ Reintentos: \(.summary.totalRetries)",
            "  â±ï¸  DuraciÃ³n: \(.metadata.totalDuration)"
        ' "$LATEST_REPORT"
    else
        log "ğŸ“‹ Instala 'jq' para ver el resumen: brew install jq"
    fi

    echo ""
    log "ğŸ“ Ver reporte completo: cat $LATEST_REPORT | jq ."
fi

# PASO 6: STATUS FINAL DEL LOTE
log_section "ğŸ“‹ PASO 6: STATUS FINAL DEL LOTE"
node lote-manager.js status

# OPCIONAL: Auto-commit y push (comentado por defecto)
# log_section "ğŸš€ PASO 7: PUBLICACIÃ“N (OPCIONAL)"
# log "âš ï¸  Auto-publicaciÃ³n desactivada. Revisar propiedades manualmente."
# log "ğŸ’¡ Para publicar: git add . && git commit -m 'Propiedades semana $(date +%Y-%m-%d)' && git push"

# Descomentar las siguientes lÃ­neas para auto-publicar:
# if [ -z "$DRY_RUN" ]; then
#     log "ğŸ“¦ Creando commit..."
#     git add .
#     git commit -m "Propiedades semana $(date +%Y-%m-%d) - Auto-scraping"
#     git push
#     log "âœ… Cambios publicados a GitHub"
# fi

# ============================================================================
# FINALIZACIÃ“N
# ============================================================================

log_section "âœ… PIPELINE COMPLETADO EXITOSAMENTE"

log "ğŸ“Š Archivos generados:"
log "  - URLs: $LATEST_URLS"
log "  - AuditorÃ­a: $LATEST_AUDIT"
log "  - Reporte: $LATEST_REPORT"
log ""
log "ğŸ“… PrÃ³xima ejecuciÃ³n: $(date -v+7d '+%Y-%m-%d %H:%M')"
log ""
log "ğŸ‰ Â¡Listo! Revisar propiedades scrapeadas antes de publicar."

exit 0
