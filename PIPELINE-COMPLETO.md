# üîÑ PIPELINE COMPLETO DE SCRAPING - INMUEBLES24

Sistema end-to-end automatizado para extracci√≥n, auditor√≠a, gesti√≥n y scraping de propiedades.

---

## üìä Arquitectura del Pipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     PIPELINE INMUEBLES24                            ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  1Ô∏è‚É£  EXTRACTOR          ‚Üí  URLs + Metadata + HTTP Verification     ‚îÇ
‚îÇ       ‚Üì                                                             ‚îÇ
‚îÇ  2Ô∏è‚É£  AUDITOR            ‚Üí  Filtrar Duplicadas + CSV Hist√≥rico      ‚îÇ
‚îÇ       ‚Üì                                                             ‚îÇ
‚îÇ  3Ô∏è‚É£  LOTE MANAGER       ‚Üí  Batch Tracking + Metadata + Backups     ‚îÇ
‚îÇ       ‚Üì                                                             ‚îÇ
‚îÇ  4Ô∏è‚É£  ORQUESTADOR        ‚Üí  Reintentos + Progress + Notificaciones  ‚îÇ
‚îÇ       ‚Üì                                                             ‚îÇ
‚îÇ  5Ô∏è‚É£  SCRAPER            ‚Üí  Puppeteer + Photos + HTML               ‚îÇ
‚îÇ       ‚Üì                                                             ‚îÇ
‚îÇ  6Ô∏è‚É£  PUBLICACI√ìN        ‚Üí  GitHub Pages + Verificaci√≥n             ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üéØ Componentes del Pipeline

### **1Ô∏è‚É£ Extractor de URLs** (`1extractorurlinmuebles24.js`)

**Entrada:** URL de b√∫squeda de Inmuebles24
```
https://www.inmuebles24.com/venta/casas/culiacan-sinaloa/3000000-4000000-pesos/
```

**Proceso:**
- Scraping con Puppeteer (navegaci√≥n autom√°tica)
- Paginaci√≥n autom√°tica (todas las p√°ginas disponibles)
- Extracci√≥n de criterios de b√∫squeda (ciudad, rango precio, tipo)
- **Verificaci√≥n HTTP HEAD** para detectar URLs removidas
- Clasificaci√≥n: v√°lidas, bloqueadas (403), removidas

**Salida:**
```
urls-inmuebles24-2025-10-26-16-35-21-valid.txt     (solo URLs usables)
urls-inmuebles24-2025-10-26-16-35-21-removed.txt   (URLs removidas)
urls-inmuebles24-2025-10-26-16-35-21.json          (metadata completa)
```

**Metadata generada:**
```json
{
  "metadata": {
    "timestampISO": "2025-10-26T16:35:21.349Z",
    "searchCriteria": {
      "type": "Casas",
      "city": "Culiac√°n",
      "priceRange": "$3,000,000 - $4,000,000"
    },
    "pagesProcessed": 5
  },
  "statistics": {
    "totalExtracted": 150,
    "validUrls": 130,
    "blockedUrls": 15,
    "removedUrls": 5
  }
}
```

**Comando:**
```bash
node 1extractorurlinmuebles24.js "SEARCH_URL"
```

---

### **2Ô∏è‚É£ Auditor de URLs** (`auditor-urls-inmuebles24.js`)

**Entrada:** Archivo TXT con URLs del extractor

**Proceso:**
- Cargar base de datos de propiedades scrapeadas (`inmuebles24-scraped-properties.json`)
- Detectar duplicadas por Property ID
- Opcionalmente: re-verificar HTTP status
- Auto-descartar URLs removidas (con flag `--auto-discard`)
- Generar estad√≠sticas completas

**Salida:**
```
audit-2025-10-26-16-41-36.json                     (resultados detallados)
audit-2025-10-26-16-41-36-nuevas.txt              (solo URLs nuevas)
audit-history.csv                                  (hist√≥rico acumulativo)
```

**CSV hist√≥rico:**
```csv
timestamp,inputFile,totalUrls,nuevas,nuevasUsables,nuevasTumbadas,duplicadas,autoDescartadas,durationSeconds
2025-10-26T16:41:36.411Z,urls-fresh-30.txt,30,12,10,2,18,2,0.45
```

**Comando:**
```bash
node auditor-urls-inmuebles24.js urls-inmuebles24-*-valid.txt
node auditor-urls-inmuebles24.js urls-*.txt --auto-discard --skip-http-check
```

---

### **3Ô∏è‚É£ Gestor de Lotes** (`lote-manager.js`)

**Entrada:** Archivo TXT de URLs auditadas (nuevas)

**Proceso:**
- Crear lote con metadata completa (precio, ciudad, tipo, notas)
- Tracking de progreso (procesadas, fallidas, pendientes)
- Sistema de backups autom√°ticos (pre-init, pre-restore, checkpoints)
- Event history completo
- 8 comandos disponibles

**Salida:**
```
1depuracionurlinmuebles24.json                     (lote activo)
backups-lotes/lote-backup-YYYY-MM-DD-HH-MM-SS.json (backups autom√°ticos)
```

**Estructura Version 2.0:**
```json
{
  "metadata": {
    "generadoEn": "2025-10-26T16:48:15.760Z",
    "rangoPrecio": "3M-4M",
    "ciudad": "Culiac√°n, Sinaloa",
    "tipo": "Casas en Venta",
    "notas": "Lote semanal de propiedades premium"
  },
  "progreso": {
    "totalUrls": 10,
    "procesadas": 3,
    "fallidas": 1,
    "pendientes": 6,
    "porcentajeCompletado": "30.00%"
  },
  "urls": [...],
  "historial": [...]
}
```

**Comandos:**
```bash
# Crear lote
node lote-manager.js init audit-nuevas.txt --rango-precio "3M-4M" --ciudad "Culiac√°n"

# Ver progreso
node lote-manager.js status

# Marcar procesada/fallida
node lote-manager.js mark-processed 147696056
node lote-manager.js mark-failed 147696056 "Timeout"

# Backup/restore
node lote-manager.js backup
node lote-manager.js restore
node lote-manager.js list-backups
```

---

### **4Ô∏è‚É£ Orquestador** (`orchestrator.js`) ‚≠ê **NUEVO**

**Entrada:** Lote activo (`1depuracionurlinmuebles24.json`)

**Proceso:**
- Leer URLs pendientes del lote
- Para cada URL:
  - Ejecutar scraper con timeout (3 min default)
  - **Reintentos autom√°ticos** (2-3 intentos)
  - **Backoff exponencial** (5s ‚Üí 10s ‚Üí 20s)
  - Capturar errores y tiempos
  - Actualizar lote-manager (procesada/fallida)
- Generar reporte final JSON
- **Notificaciones opcionales** (Email/Slack)

**Salida:**
```
reports/orchestrator-2025-10-26-23-57-06.json     (reporte detallado)
```

**Reporte generado:**
```json
{
  "metadata": {
    "startTime": "2025-10-26T23:50:00.000Z",
    "totalDuration": "8m 23s",
    "loteInfo": {
      "rangoPrecio": "3M-4M",
      "ciudad": "Culiac√°n, Sinaloa"
    }
  },
  "summary": {
    "totalUrls": 10,
    "successful": 7,
    "failed": 3,
    "successRate": "70.00%",
    "totalRetries": 5,
    "avgDuration": "50s"
  },
  "results": [...]
}
```

**Reintentos con Backoff:**
```
Intento 1: Ejecutar inmediatamente
  ‚Üì (fallo)
Esperar 5 segundos
  ‚Üì
Intento 2: Ejecutar
  ‚Üì (fallo)
Esperar 10 segundos
  ‚Üì
Intento 3: Ejecutar
  ‚Üì (fallo ‚Üí marcar como fallida)
```

**Notificaciones:**

**Email (SMTP):**
```
Asunto: ‚úÖ Scraping completado: 7/10 exitosas

Duraci√≥n total: 8m 23s
‚úÖ Exitosas: 7 (70.00%)
‚ùå Fallidas: 3
üîÑ Reintentos totales: 5

Lote: Culiac√°n, Sinaloa ¬∑ 3M-4M
Reporte: reports/orchestrator-2025-10-26-23-57-06.json
```

**Slack (Webhook):**
```
‚úÖ Scraping completado

Exitosas: 7/10    |    Fallidas: 3
Duraci√≥n: 8m 23s  |    Tasa √©xito: 70.00%

Lote: Culiac√°n, Sinaloa ¬∑ 3M-4M
```

**Comandos:**
```bash
# Procesar lote actual
node orchestrator.js

# Con notificaciones
node orchestrator.js --notify email
node orchestrator.js --notify slack

# Dry-run (simular)
node orchestrator.js --dry-run

# Personalizar reintentos
node orchestrator.js --max-retries 3
```

---

### **5Ô∏è‚É£ Scraper** (`inmuebles24culiacanscraper.js`)

**Entrada:** URL individual de propiedad

**Proceso:**
- Scraping con Puppeteer (headless mode)
- Detecci√≥n autom√°tica de ciudad
- **Sistema inteligente de direcciones** (scoring autom√°tico)
- Descarga de TODAS las fotos
- Generaci√≥n HTML con master template
- SEO completo (meta tags, Schema.org, Open Graph)
- Auto-add al mapa modal de la ciudad
- **Detecci√≥n de duplicados** por Property ID

**Salida:**
```
culiacan/casa-venta-slug/index.html               (p√°gina completa)
culiacan/casa-venta-slug/images/foto-*.jpg        (fotos optimizadas)
inmuebles24-scraped-properties.json               (DB actualizada)
```

**Comando:**
```bash
node inmuebles24culiacanscraper.js "PROPERTY_URL"
```

---

### **6Ô∏è‚É£ Publicaci√≥n** (Manual)

**Proceso:**
- Revisi√≥n manual de propiedades scrapeadas
- Verificaci√≥n de calidad (fotos, datos, SEO)
- Commit + push a GitHub
- Deployment autom√°tico v√≠a GitHub Pages

**Comando:**
```bash
git add .
git commit -m "Propiedades semana 2025-10-26"
git push
# GitHub Pages auto-deploys (1-2 minutos)
```

---

## üöÄ Workflow Completo

### **Opci√≥n 1: Manual (Control Total)**

```bash
# 1. EXTRAER URLs
node 1extractorurlinmuebles24.js "https://www.inmuebles24.com/venta/casas/culiacan/3000000-4000000-pesos/"

# 2. AUDITAR
node auditor-urls-inmuebles24.js urls-inmuebles24-*-valid.txt

# 3. CREAR LOTE
node lote-manager.js init audit-*-nuevas.txt \
    --rango-precio "3M-4M" \
    --ciudad "Culiac√°n, Sinaloa" \
    --tipo "Casas en Venta" \
    --notas "Lote semanal premium"

# 4. ORQUESTAR SCRAPING
node orchestrator.js --notify slack

# 5. REVISAR REPORTE
cat reports/orchestrator-*.json | tail -1 | jq '.summary'

# 6. PUBLICAR (manual)
# Revisar propiedades ‚Üí git add . ‚Üí git commit ‚Üí git push
```

### **Opci√≥n 2: Script Automatizado**

```bash
# Ejecutar pipeline completo con un comando
./weekly-scraping.sh --notify slack

# O en dry-run para testing
./weekly-scraping.sh --dry-run
```

### **Opci√≥n 3: Automatizaci√≥n con Cron**

```bash
# Agregar a crontab
crontab -e

# Ejecutar cada lunes a las 2 AM
0 2 * * 1 cd /path/to/project && ./weekly-scraping.sh --notify slack >> logs/scraping.log 2>&1
```

---

## üìä M√©tricas y Reportes

### **An√°lisis de Reportes del Orquestador**

```bash
# Ver √∫ltimo reporte (resumen)
cat $(ls -t reports/orchestrator-*.json | head -1) | jq '.summary'

# Ver todas las fallidas
jq '.results[] | select(.status=="failed")' reports/orchestrator-*.json

# Calcular tasa de √©xito promedio
jq -r '.summary.successRate' reports/orchestrator-*.json | \
    awk '{sum+=$1; n++} END {print sum/n "%"}'

# Listar propiedades m√°s lentas
jq -r '.results[] | "\(.durationMs)ms - \(.propertyId)"' reports/orchestrator-*.json | \
    sort -rn | head -10
```

### **An√°lisis del CSV Hist√≥rico del Auditor**

```bash
# Ver √∫ltimas 10 corridas
tail -10 audit-history.csv | column -t -s,

# Total de URLs procesadas
awk -F, 'NR>1 {sum+=$3} END {print sum}' audit-history.csv

# Promedio de duplicadas
awk -F, 'NR>1 {sum+=$7; n++} END {print sum/n}' audit-history.csv

# Propiedades nuevas por mes
awk -F, 'NR>1 {print substr($1,1,7)}' audit-history.csv | uniq -c
```

---

## üîß Configuraci√≥n y Variables

### **Variables de Entorno (.env)**

```env
# Orquestador
MAX_RETRIES=2
INITIAL_BACKOFF=5
SCRAPER_TIMEOUT=180000

# Notificaciones Email
EMAIL_ENABLED=true
EMAIL_TO=hector@ejemplo.com
SMTP_HOST=smtp.gmail.com
SMTP_USER=tu-email@gmail.com
SMTP_PASS=xxxx-xxxx-xxxx-xxxx

# Notificaciones Slack
SLACK_ENABLED=true
SLACK_WEBHOOK=https://hooks.slack.com/services/YOUR/WEBHOOK/URL
```

### **Configuraci√≥n del Script Semanal**

Editar `weekly-scraping.sh`:

```bash
# URL de b√∫squeda
SEARCH_URL="https://www.inmuebles24.com/venta/casas/culiacan-sinaloa/3000000-4000000-pesos/"

# Metadata
PRICE_RANGE="3M-4M"
CITY="Culiac√°n, Sinaloa"
PROPERTY_TYPE="Casas en Venta"
```

---

## üìà Estad√≠sticas de Rendimiento

### **Benchmark Real (50 propiedades)**

```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  üìä PIPELINE COMPLETO - ESTAD√çSTICAS                         ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

1Ô∏è‚É£  Extractor:        2m 15s  (150 URLs, 5 p√°ginas)
2Ô∏è‚É£  Auditor:          0.5s    (12 nuevas, 138 duplicadas)
3Ô∏è‚É£  Lote Manager:     0.2s    (init + metadata)
4Ô∏è‚É£  Orquestador:      42m 15s (scraping de 12 propiedades)
    - Exitosas:       10 (83.3%)
    - Fallidas:       2
    - Reintentos:     3
    - Promedio/prop:  3m 30s

üìä Total: 45 minutos (completamente automatizado)
```

### **Tasa de √âxito Hist√≥rica**

```
Mes         | Total | Exitosas | Tasa √âxito
------------|-------|----------|------------
Oct 2025    |   50  |    43    |   86.0%
Sep 2025    |   38  |    35    |   92.1%
Ago 2025    |   45  |    41    |   91.1%
```

**Promedio:** 89.7% de √©xito

---

## üîç Troubleshooting

### **Problema: Extractor no encuentra URLs**

**Soluci√≥n:**
```bash
# Verificar URL de b√∫squeda
# Probar manualmente en browser
# Revisar logs para errores de Cloudflare
```

### **Problema: Auditor marca todo como duplicado**

**Soluci√≥n:**
```bash
# Verificar base de datos
cat inmuebles24-scraped-properties.json | jq '. | length'

# Si est√° corrupta, restaurar desde backup
git checkout HEAD -- inmuebles24-scraped-properties.json
```

### **Problema: Orquestador falla con timeout**

**Soluci√≥n:**
```bash
# Aumentar timeout en .env
SCRAPER_TIMEOUT=300000  # 5 minutos

# O reducir carga de Cloudflare
# Agregar delay entre propiedades
```

### **Problema: Notificaciones no llegan**

**Soluci√≥n:**
```bash
# Email: verificar credenciales SMTP
# Generar nueva contrase√±a de aplicaci√≥n en Gmail

# Slack: probar webhook manualmente
curl -X POST -H 'Content-type: application/json' \
    --data '{"text":"Test"}' \
    YOUR_WEBHOOK_URL
```

---

## üìö Documentaci√≥n Adicional

- **`WORKFLOW-EXTRACTOR-AUDITOR.md`** - Documentaci√≥n Extractor + Auditor
- **`ORCHESTRATOR-README.md`** - Documentaci√≥n completa del Orquestador
- **`lote-manager.js`** - Comentarios inline con ejemplos de uso
- **`weekly-scraping.sh`** - Script con logging y error handling

---

## üéØ Mejores Pr√°cticas

### ‚úÖ **DO:**
- Ejecutar `--dry-run` antes de procesar lotes grandes
- Configurar notificaciones para lotes de >10 URLs
- Revisar reportes despu√©s de cada ejecuci√≥n
- Limpiar reportes viejos mensualmente
- Mantener backups del lote antes de operaciones cr√≠ticas
- Usar el script semanal para automatizaci√≥n consistente

### ‚ùå **DON'T:**
- No usar reintentos excesivos (>3) - puede saturar Inmuebles24
- No reducir backoff por debajo de 3 segundos
- No ignorar reportes de fallos - investigar causas
- No ejecutar m√∫ltiples orquestadores en paralelo
- No commitear `.env` con credenciales reales
- No publicar sin revisar propiedades primero

---

## üéâ Ventajas del Pipeline

### **Antes (Manual):**
```
1. Buscar propiedades en Inmuebles24 (30 min)
2. Copiar/pegar URLs manualmente (15 min)
3. Verificar una por una qu√© ya tenemos (20 min)
4. Scrapear una por una (1h 30min)
5. Revisar y publicar (30 min)

Total: ~3 horas de trabajo manual
```

### **Ahora (Automatizado):**
```
1. Ejecutar: ./weekly-scraping.sh --notify slack
2. Esperar notificaci√≥n (~45 min)
3. Revisar propiedades (15 min)
4. Publicar (git push)

Total: 15 minutos de trabajo manual
Ahorro: 88% de tiempo
```

---

## üìû Soporte y Mantenimiento

**Mantenimiento Regular:**
- Limpiar `reports/` cada 30 d√≠as: `find reports/ -mtime +30 -delete`
- Revisar `audit-history.csv` mensualmente
- Backup de `inmuebles24-scraped-properties.json` semanal
- Actualizar `.env` si cambian credenciales

**Actualizaciones Futuras:**
- [ ] Dashboard web para visualizar reportes
- [ ] Integraci√≥n con Google Sheets para tracking
- [ ] Auto-publicaci√≥n con revisi√≥n autom√°tica de calidad
- [ ] Scraping multi-thread (procesar 3-5 propiedades en paralelo)

---

**Versi√≥n del Pipeline:** 4.0
**√öltima actualizaci√≥n:** Octubre 2025
**Mantenido por:** Hector Palazuelos + Claude

**Repositorio:** https://github.com/hectorpalazuelos/casas-en-venta
**Documentaci√≥n:** `PIPELINE-COMPLETO.md` (este archivo)
